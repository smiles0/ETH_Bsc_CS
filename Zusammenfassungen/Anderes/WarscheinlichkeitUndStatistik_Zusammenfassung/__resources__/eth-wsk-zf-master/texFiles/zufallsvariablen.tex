\section{Zufallsvariablen}

\subsection{Diskrete Zufallsvariablen}

\subsubsection{Gewichtsfunktion}
Die Summe aller Gewichte ist immer 1 und die Werte immer im Intervall [0,1]:
\[
\sum\limits_{i=1}^{\infty}f(x)=1
\]
\subsubsection{Verteilungsfunktion}

\subsection{Stetige Zufallsvariablen}

\subsubsection{Dichtefunktion}

Die Fläche unter der Dichtefunktion ist immer 1 und die Werte immer im Intervall [0,1]: 
\[
\int\limits_{-\infty}^{\infty}f(x)dx=1
\]

\textbf{Bemerkungen}
\begin{itemize}
\item Durch Integrieren der Dichtefunktion erhält man die Verteilungsfunktion.
\end{itemize}

\subsubsection{Verteilungsfunktion}
\[
F(x) = P[X \leq x] = \int\limits_{-\infty}^{x}f(u)du
\]

\textbf{Bemerkungen}
\begin{itemize}
\item Durch Ableiten der Verteilungsfunktion erhält man die Dichtefunktion.
\end{itemize}

\subsection{Gemeinsame Verteilungen}

\textbf{Gemeinsame Verteilungsfunktion:} Die gemeinsame Verteilungsfunktion von $n$ Zufallsvariablen $X_1,...,X_n$ ist die Abbildung $F:\mathbb{R}^n\rightarrow [0,1]$,
\[
F(t_1,...,t_n):=P[X_1\leq t_1,...,X_n\leq t_n]
\]

\textbf{Gemeinsame Gewichtsfunktion:} Falls $X_1,...,X_n$ \emph{diskrete} Zufallsvariablen sind, ist ihre gemeinsame Gewichtsfunktion $p:\mathbb{R}^n\rightarrow [0,1]$ definiert durch
\[
p(x_1,...,x_n):=P[X_1=x_1,...,X_n=x_n]
\]

\textbf{Gemeinsame Dichte:} Seien $X_1,...,X_n$ \emph{stetige} Zufallsvariablen mit gemeinsamer Verteilungsfunktion $F(t_1,...,t_n)$. Die Funktion $f:\mathbb{R}^n\rightarrow [0,\infty)$ heisst \emph{gemeinsame Dichte} von $X_1,...,X_n$, falls für alle $t_i\in\mathbb{R}$ gilt
\[
F(t_1,...,t_n)=\int\limits_{-\infty}^{t_1}...\int\limits_{-\infty}^{t_n}f(x_1,...,x_n)\ dx_n...dx_1
\]

\subsubsection{Randverteilungen}
Seien $X$ und $Y$ Zufallsvariablen mit gemeinsamer Verteilungsfunktion $F_{XY}$, dann ist die Randverteilung $F_X:\mathbb{R}\rightarrow [0,1]$ von $X$ definiert durch
\[
F_X=P[X\leq x]=P[X\leq x,Y\leq\infty]=\lim_{y\to\infty}F_{XY}(x,y)
\]

Für zwei \emph{diskrete} Zufallsvariablen $X$ und $Y$ mit gemeinsamer Gewichtsfunktion $f_{XY}(x,y)$ ist die Gewichtsfunktion der Randverteilung von $X$ gegeben durch
\[
f_X=P[X=x]=\sum\limits_{j}P[X=x,Y=y_j]=\sum\limits_{j}f_{XY}(x,y_j)
\]

Für zwei \emph{stetige} Zufallsvariablen $X$ und $Y$ mit gemeinsamer Dichte $f_{XY}(x,y)$ ist die Dichtefunktion der Randverteilung (Randdichte) von $X$ gegeben durch
\[
f_X(x)=\int\limits_{\infty}^{\infty}f_{XY}(x,y)\ dy
\]

\subsubsection{Bedingte Verteilung}
\textbf{Bedingte Gewichtsfunktion:} Seien $X$ und $Y$ \emph{diskrete} Zufallsvariablen mit gemeinsamer Gewichtsfunktion $f_{XY}(x,y)$, dann ist die bedingte Gewichtsfunktion $f_{X|Y}(x|y)$ von $X$ gegeben $Y$ definiert durch
\[
f_{X|Y}(x|y)=P[X=x|Y=y]=\frac{f_{XY}(x,y)}{f_Y(y)}
\]

\textbf{Bedingte Dichte:} Für zwei \emph{stetige} Zufallsvariablen $X$ und $Y$ mit gemeinsamer Dichte $f_{XY}(x,y)$ ist die bedingte Dichte $f_{X|Y}$ von $X$ gegeben $Y$ definiert durch
\[
f_{X|Y}(x|y)=\frac{f_{XY}(x,y)}{f_Y(y)}
\]

\subsection{Funktionen diskreter Zufallsvariablen}

\subsubsection{Summe von Zufallsvariablen}
...

\subsubsection{Produkte von Zufallsvariablen}
...

\subsection{Funktionen stetiger Zufallsvariablen}
\textbf{Fall \boldmath$Y=aX+b$:} \\
Verteilungsfunktion:
\[
\begin{array}{rcl}
	F_Y(t) & = & P[Y\leq t]=P[aX+b\leq t]= \\
	& = & P[X\leq \frac{t-b}{a}]=F_X(\frac{t-b}{a}) \\
\end{array}
\]

Dichtefunktion:

\[
f_Y(t)=\frac{1}{a}f_X\left(\frac{t-b}{a}\right)
\]

\textbf{Fall \boldmath$Y=X^2$:} \\
Verteilungsfunktion:
\[
\begin{array}{rcl}
	F_Y(t) & = & P[Y\leq t]=P[X^2\leq t]=P[-\sqrt{t}\leq t\leq\sqrt{t}] \\
	& = & F_X(\sqrt{t})-F_X(-\sqrt{t}) \\
\end{array}
\]

Dichtefunktion:
\[
f_Y(t)=\frac{1}{\sqrt{2\pi}}t^{-\frac{1}{2}}e^{-\frac{1}{2}t}
\]

\textbf{Fall \boldmath$Y=\frac{1}{X}$:} \\
Verteilungsfunktion:
\[
\begin{array}{rcl}
	F_Y(t) & = & P[Y\leq t]=P[\frac{1}{X}\leq t] \\
	& = & P[X\geq\frac{1}{t}]=1-P[X\leq\frac{1}{t}]=1-F_X(\frac{1}{t}) \\
\end{array}
\]

Dichtefunktion:
\[
f_Y(t)=\frac{1}{t^2}f_X\left(\frac{1}{t}\right)
\]

\subsection{Chebyshev-Ungleichung}
Die Chebyshev-Ungleichung liefert eine Abschätzung von Wahrscheinlichkeiten, auch wenn die genaue Verteilungsfunktion nicht bekannt ist. Es muss nur der Erwartungswert $E[X]$ und die Varianz $Var[X] < \infty$ einer Zufallsvariablen $X$ bekannt sein, dann gilt für jedes $k > 0$:
\[
P\left[|X - E[X]| \geq k \right] \leq \frac{Var[X]}{k^2}
\]

\subsection{Eigenschaften von Zufallsvariablen}

\subsubsection{Unabhängigkeit}
Zwei Zufallsvariablen $X$ und $Y$ heissen unabhängig, wenn stets gilt
\[
\begin{array}{rcl}
	F(x,y) & = & F_X(x) \cdot F_Y(y) \\
	f(x,y) & = & f_X(x) \cdot F_Y(y) \\
\end{array}
\]
wobei $F_X(x), F_X(y)$ die Verteilungsfunktionen und $f_X(x), f_Y(y)$ die Gewichts- bzw. Dichtefunktionen von $X$ und $Y$ sind.

\subsubsection{Unkorreliert}
Zwei Zufallsvariablen $X$ und $Y$ heissen \emph{unkorreliert}, falls gilt $Cov(X,Y)=0$.

Eine Menge von Zufallsvariablen $X_1,X_2,...,X_n$ heissen \emph{paarweise unkorreliert}, wenn alle Paare $X_i,X_j$ mit $i\neq j$ unkorreliert sind.

\subsection{Erwartungswert}
Der Erwartungswert ist das langfristige Durchschnittsergebnis bei einem Zufallsexperiment mit vielen Wiederholungen.

\vspace{10pt}

Diskrete Verteilung:
\[
E[X]=\sum\limits_{i} x_i\cdot f(x_i)
\]

Stetige Verteilung:
\[
E[X]=\int\limits_{-\infty}^{\infty}x\cdot f(x)dx
\]

\subsubsection{Additionssatz für Erwartungswerte}
Der Erwartungswert einer aus $n$ (diskreten oder stetigen) Zufallsvariablen $X_1,X_2,...,X_n$ gebildeten Summe
\[
Z=a_1X_1+a_2X_2+...+a_nX_n
\]
ist gleich der Summe der Erwartungswerte der einzelnen Zufallsvariablen:
\[
E[Z]=a_1E[X_1]+a_2E[X_2]+...+a_nE[X_n]
\]

\subsubsection{Multiplikationssatz für Erwartungswerte}
Der Erwartungswert eines aus $n$ \emph{stochastisch unabhängigen} (diskreten oder stetigen) Zufallsvariablen $X_1,X_2,...,X_n$ gebildeten Produkts
\[
Z=X_1\cdot X_2\cdot ...\cdot X_n
\]
ist gleich dem Produkt der Erwartungswerte der einzelnen Zufallsvariablen:
\[
E[Z]=E[X_1\cdot X_2\cdot ...\cdot X_n]=E[X_1]\cdot E[X_2]\cdot ...\cdot E[X_n]
\]

\subsubsection{Formeln für 2. Moment}
Dieses wird z.B. für die Momenten-Methode und zur Berechnung der Varianz benötigt.

\vspace{10pt}

Diskrete Verteilung:
\[
E[X^2]=\sum\limits_{i} x_i^2\cdot f(x_i)
\]

Stetige Verteilung:
\[
E[X^2]=\int\limits_{-\infty}^{\infty}x^2\cdot f(x)dx
\]

\subsubsection{Weitere Rechenregeln}
\[
\begin{array}{rcl}
	E[a] & = & a \text{(für a = const.)} \\
	E[aX] & = & a \cdot E[X] \text{(für a = const.)} \\
	E[aX + b] & = & a \cdot E[X] + b \\	
	E[E[X]] & = & E[X] \\
\end{array}
\]

\subsection{Varianz}
Die Varianz ist ein Streuungsmass, also ein Mass für die Abweichung einer Zufallsvariable von ihrem Erwartungswert.

\vspace{10pt}

Diskrete Verteilung:
\[
Var[X]=\sum\limits_{i}(x_i-E[X])^2\cdot f(x_i)
\]

Stetige Verteilung:
\[
Var[X]=\int\limits_{-\infty}^{\infty}(x-E[X])^2\cdot f(x)dx
\]

Vereinfachte Berechnung:
\[
\begin{array}{c}
	Var[X] = E[X^2] - E[X]^2 \\
\end{array}
\]

\subsubsection{Additionssatz für Varianzen}
Die Varianz einer aus $n$ \emph{stochastisch unabhängigen} (diskreten oder stetigen) Zufallsvariablen $X_1,X_2,...,X_n$ gebildeten Summe
\[
Z=a_1X_1+a_2X_2+...+a_nX_n
\]
ist gleich der Summe der Varianzen der einzelnen Zufallsvariablen:
\[
Var[Z]=a_1^2Var[X_1]+a_2^2Var[X_2]+...+a_n^2Var[X_n]
\]

\subsubsection{Weitere Rechenregeln}
\[
\begin{array}{rcl}
	Var[aX + b] & = & a^2 \cdot Var[X] \\
	Var[aX + bY] & = & a^2 \cdot Var[X] + b^2 \cdot Var[Y] + \\
	& &  2ab \cdot Cov[X,Y] \\
\end{array}	
\]

\subsection{Kovarianz}
Die Kovarianz ist ein Mass für den Zusammenhang zwischen zwei Zufallsvariablen $X$ und $Y$ bzw. der Streuung zwischen ihnen.
\[
\begin{array}{rcl}
	Cov[X,Y] & = & E[(X - E[X])(Y - E[Y])] \\
	Cov[X,Y] & = & E[XY] - E[X] \cdot E[Y] \\
	Cov[X,Y] & = & \frac{1}{2} \cdot \left(Var[X + Y] - Var[X] - Var[Y] \right)	\\
	Cov[X,Y] &= & Cov[Y,X] \\
	Cov[X,X] & = & Var[X] \\
	Cov[aX + b,Y] & = & a \cdot Cov[X,Y] \\
	Cov[X + Y,Z] & = & Cov[X,Z] + Cov[Y,Z] \\
	\forall a \in \mathbb{R}: Cov[X,a] & = & 0 \\
	\forall b \in \mathbb{R}: Cov[X,bY] & = & b \cdot Cov[X,Y] \\
\end{array}
\]

\subsection{Standardabweichung}
\[
sd[X] = \sqrt{Var[X]}
\]